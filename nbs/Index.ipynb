{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d803ba8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Task Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74468db3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As a sales intelligence platform, we’re collecting all kinds of information about different companies. The purpose of this is to make a more informed decision about which companies we or our clients should target (try to win as a customer) and which not. At the moment, for example, we try to find out what is the industry of the company, what is its business model, who are its customers (businesses or private people, etc.). There could be different sources for this information; however we only use openly available information on the internet. It could be a linkedin page of the company, any type of news- and blog- posts or the company webpage. Especially the latter is a particularly good source of information, since:\n",
    "\n",
    "    There are no limitations on what a company can present. No size limitation, for example.\n",
    "\n",
    "    Usually there is no anti scraping protection - companies do not mind their webpages to be scraped since they actually want to make the information about themselves as much spread out as possible\n",
    "\n",
    "On the other hand, it’s not so easy to extract any specific information from the company webpage, since there is no predefined structure - each website has its own, sometimes unique, design and structure.\n",
    "\n",
    "We provide you with a dataset, that is a list of the company websites.\n",
    "\n",
    "https://drive.google.com/file/d/1eCOboCXzUdEXeDgOj3rdcBvac5Mq1f7f/view?usp=sharing\n",
    "\n",
    "The challenge consists of several tasks.\n",
    "\n",
    "    Come up with an idea of what kind of useful information we could extract from the website. This information should be helpful for UserGems to decide if the company in question could be a good target for selling the UG platform to them. This useful piece of information we usually call a signal. In this first task we don’t evaluate your skills as a Data Scientist, but more the ability to think from a business perspective.\n",
    "\n",
    "    Find a way to scrape and extract the suggested signal from the webpage. You can use any kind of scraping service to get the contents of the webpage and also use LLMs for parsing the data. We can give you limited access to OpenAI API if necessary. This access will have a limitation on how many tokens you can use. If you run out of the tokens, let us know and we might increase your limit.\n",
    "\n",
    "    Using the dataset you’ve created with the LLM, train a local model to extract the signal from the webpage. The point of training our own model is to replace calling the OpenAI API, for extraction of the signal, which is slow and costly. We do not expect this model to be very accurate, but you need to provide the evaluation of how good your model is. It’s up to you what model to use. It can, for example, be a small transformer model from Huggingface. In case you need GPUs for training the model, you can use the freely available google colab notebooks with GPU support.\n",
    "\n",
    "\n",
    "Important Points\n",
    "\n",
    "❗Be aware that this is an open-ended challenge. Don’t get lost in the multitude of nuances, but rather focus on some specific points/signals that potentially could bring value to our product. We value a simple solution that works rather than excessive theoretical considerations.\n",
    "\n",
    "❗Consider that we don’t expect you to scrape all webpages in the dataset, but rather to come up with a working solution that could easily be extended to large datasets. You might use additional columns in the dataset to filter out the companies that could be more relevant to the signal you come up with.\n",
    "\n",
    "Time & Compensation\n",
    "\n",
    "We expect you to spend around one full working day on the problem. \n",
    "\n",
    "Your effort will be compensated with 350 Euros. \n",
    "\n",
    "During this challenge you might want to use openai. \n",
    "\n",
    "For that you can use the following API key: https://share.1password.com/s#t8bY_OHbkfMEa6f25au1wBDyWAgKqty_YDAp5OSrEqo\n",
    "If you have any problems with the access or any other questions - you can reach out to us, use the option \"reply to all\", my colleagues Andrey or Jalob are in cc.\n",
    "\n",
    "Best Regards,\n",
    "\n",
    "Elena\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459564b3",
   "metadata": {},
   "source": [
    "# 1. Signals for Usergems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1878a9ba",
   "metadata": {},
   "source": [
    "Here are some UG signal ideas:\n",
    "- From a list of signals, what would be the top 3 for a company, how well do they match/how relevant are they (the company description)?\n",
    "    - Hi X, ... at UG we could give you the following 3 signals (that you can't get anywhere else):\n",
    "        - S1\n",
    "        - S2\n",
    "        - S3\n",
    "- Match closest customer\n",
    "    - From a list of UG customers, who is the closest one? And then match up (and qualify if it's a good match)\n",
    "    - Hi X, we work with {company name}, who similar to you is doing X. They use UG for Y. Want to check it out?\n",
    "- Relying on jobs\n",
    "     - are they hiring?\n",
    "     - are they hiring AE/SDRs?\n",
    "     - new sales inititiatives?\n",
    "     - are they advertising in their jobs any of the tools you integrate with?\n",
    "- Do they have a product / service that needs a sales team (i.e. not self serve)\n",
    "    - can't use this in copy, but gets rid of \"university press\", gets rid of not launched products, gets rid of self-serve products\n",
    "     \n",
    "     \n",
    "From a business perspective, finetuning (a local model) is not worth it in this case.\n",
    "- 60k companies -- not that much cost savings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84df7762",
   "metadata": {},
   "source": [
    "# 2. After manually reviewing first 20 sites (CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8707844b",
   "metadata": {},
   "source": [
    "The input data is quite noisy. Out of the first 20 companies (computer software)\n",
    "- 7 pages didn't even load\n",
    "- 2 are not CS companies\n",
    "\n",
    "After reviewing the website: another good signal is \"are they selling a product/service to end customers\"\n",
    "- gets rid of no loa\n",
    "- gets rid of \"Michigan Unversity Press\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508bc0ad",
   "metadata": {},
   "source": [
    "# 3. Improvements/tests I didn't have time for\n",
    "- Use a DB instead of a sequence of csv files\n",
    "    - even just SQLite would be good\n",
    "- Optimize scraper\n",
    "    - Use stealth mode / anti-anti-scraping tech\n",
    "    - Investigate if there are major failures\n",
    "    - Add retries\n",
    "    - Add more elaborae JS waiting if needed\n",
    "    - Record redirects for deduplication\n",
    "- html2markdown\n",
    "    - I know there is a benchmark of different repos, but couldn't find it\n",
    "    - There are also a bunch of new repos I didn't see previously\n",
    "    - Do some side-by-side comparisons for which markdown converter is the best (vs. vanially html!)\n",
    "    - Do more html stripping (i.e. what I do for images)\n",
    "        - Good way to go about it is inspect the HTML length, markdown length, and the ratios\n",
    "    - Sometimes text whitespace gets too squashed. Need to inspect where this happens\n",
    "- Invalid websites\n",
    "    - ~50% of invalid websites are actually valid, so this part can be made better.\n",
    "        - some we couldn't scrape\n",
    "        - some got mistakenly classified\n",
    "    - but it's only 10% of the list, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e08d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee298ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4051a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1fa3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
