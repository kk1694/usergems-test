{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8cd7213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from unsloth import FastLanguageModel \n",
    "from unsloth import is_bfloat16_supported\n",
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c99b09e",
   "metadata": {},
   "source": [
    "# Install Note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bbb32e",
   "metadata": {},
   "source": [
    "Note: to use this notebook, you need:\n",
    "1. a gpu machine\n",
    "2. install the following extra dependencies: https://github.com/unslothai/unsloth\n",
    "\n",
    "I used an AWS `g5.xlarge` instance with the Ubuntu pytorch image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fae4442",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7683a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 2048\n",
    "num_valid = 100\n",
    "\n",
    "train_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c9ae0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions= \"\"\"\n",
    "You are a website classifier. I'm going to give you access to a website content (converted to markdown). Your job is to determine whether the website contains jobs.\n",
    "\n",
    "You shall classify websites into the following buckets:\n",
    "- Job list: the website explicitly lists actual jobs (with titles), or links to jobs that you can apply for. There has to be 1+ job listed.\n",
    "- Empty list: the website has a section where jobs did and will apear, but right now it's empty, or company is currently not hiring. If there is a list with zero items, that also counts as empty list Even if they encourga people to send their CV, it counts as empty list if they state that they have no jobs right now. If the website mentions current roles but does not list any specific jobs, it is an empty list.\n",
    "- Link to jobs: the page does not contain job lists, but has a link to a career / job page that has it. The link could be on the same domain, a separate domain, or it could be a link to an ATS provider or job board. Note: if the navbar (or footer) has a \"Company\"/\"About\"/\"About us\" (or similar section that often contains jobs), select this option. Also, it has a button saying \"Apply\" with no further context, it still counts as a link, not open apply; unless generic applications are specifically stated.\n",
    "- Job open apply: the website says their accepting jobs, but does not list the jobs. Instead, it encourages people to apply, or email HR, or just has a rolling generic process. Note: the previous category takes precedence!\n",
    "- No jobs: the website does not have any explicit jobs, does not have a vague apply by sending HR your CV, and does not even include a link to a separate page for jobs. This is different from section 1 in that there is no mention of jobs/careers/etc.\n",
    "\n",
    "Use a waterfall approach: if the first category is satisfied (Job list), select that, then move to the next. If empty list is satisfied, select that, and so on. Categories higher up in the list take precedence.\n",
    "\n",
    "Note:\n",
    "- If the site does not list specific links AND mentions that they currently have no jobs, it is an empty list - NO MATTER if they still encourage you to apply.\n",
    "\n",
    "Examples:\n",
    "- \"While FitLife has no current openings, we're always looking for talented fitness professionals. Please check back soon\" -> Empty list\n",
    "- \"    StreamIt - Unlimited Movies and TV Shows. Enjoy the latest movies and shows without ads. Start streaming today!\" -> No jobs\n",
    "- \"    Interested in working with us? Check our [career page](https://www.acme.com/jobs) for the latest openings.\" -> Link to jobs\n",
    "- \"GreenEnergy is always looking for skilled professionals to join our mission for sustainable energy. Send us your resume.\" -> Job open apply\n",
    "- '''\n",
    "TravelPro is an award-winning travel agency offering luxury vacations and personalized travel services.\n",
    "\n",
    "    Positions available:\n",
    "    - [Travel Consultant](https://travelpro.com/jobs/travel-consultant)\n",
    "    - [Customer Service Associate](https://travelpro.com/jobs/customer-service)\n",
    "''' -> Job list\n",
    "- \"    LearnTech is always looking for new talent. While we have no current positions available, feel free to submit your resume for future consideration on our [careers portal](https://learntech.com/careers).\" -> Empty list\n",
    "- \"   ACME is always looking for talented individuals to join our team, but we currently don't have any open positions.\\n\\n    Please check back soon or submit your resume for future opportunities via our [general application form](https://acme.com/apply).\" -> Empty list\n",
    "- \"    We currently have no job openings, but you can always stay updated via our [careers page](https://bluesky.com/careers).\" -> Empty list\n",
    "- \" ACME is currently not having any open roles, but we're always looking for talented individuals. Please send us your resume.\" -> Empty list\n",
    "- \" Jobs at FitLife: \\n\\n - \\n\" -> Empty list\n",
    "\n",
    "Only answer with the classification `Job list`, `Empty list`, `Link to jobs`, `Job open apply`, `No jobs` and nothing else.\n",
    "    \"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2325c4f",
   "metadata": {},
   "source": [
    "# Set Up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6858d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>Website</th>\n",
       "      <th>scrape_status</th>\n",
       "      <th>md_status</th>\n",
       "      <th>md</th>\n",
       "      <th>html_length</th>\n",
       "      <th>md_length</th>\n",
       "      <th>valid_website</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sawa Impact Labs</td>\n",
       "      <td>https://sawa.gallery/</td>\n",
       "      <td>Success</td>\n",
       "      <td>Success</td>\n",
       "      <td>Squarespace \\- Website Expired\\n\\n\\nÂ \\nWebsite...</td>\n",
       "      <td>6998</td>\n",
       "      <td>124</td>\n",
       "      <td>valid</td>\n",
       "      <td>No jobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OpenMI at the University of Michigan</td>\n",
       "      <td>https://maizepages.umich.edu/organization/openmi</td>\n",
       "      <td>Success</td>\n",
       "      <td>Success</td>\n",
       "      <td>OpenMI \\- University of Michigan Maize Pages\\n...</td>\n",
       "      <td>39237</td>\n",
       "      <td>784</td>\n",
       "      <td>valid</td>\n",
       "      <td>No jobs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            CompanyName  \\\n",
       "0                      Sawa Impact Labs   \n",
       "1  OpenMI at the University of Michigan   \n",
       "\n",
       "                                            Website scrape_status md_status  \\\n",
       "0                             https://sawa.gallery/       Success   Success   \n",
       "1  https://maizepages.umich.edu/organization/openmi       Success   Success   \n",
       "\n",
       "                                                  md  html_length  md_length  \\\n",
       "0  Squarespace \\- Website Expired\\n\\n\\nÂ \\nWebsite...         6998        124   \n",
       "1  OpenMI \\- University of Michigan Maize Pages\\n...        39237        784   \n",
       "\n",
       "  valid_website   status  \n",
       "0         valid  No jobs  \n",
       "1         valid  No jobs  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/04b_first_status.csv\")\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f42d04d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "No jobs           1476\n",
       "Link to jobs       277\n",
       "Job open apply      48\n",
       "Job list            11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d8b8993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacky way to get exactly 200 validation examples\n",
    "df['split'] = 'train'\n",
    "df.loc[np.random.choice(len(df), size=num_valid, replace=False), 'split'] = 'valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f424b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    1900\n",
       "valid     100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c5a04e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1900, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df[df.split == 'train'].copy()\n",
    "valid = df[df.split == 'valid'].copy()\n",
    "\n",
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca204726",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59da0a62",
   "metadata": {},
   "source": [
    "Pretty much using unsloth defaults everywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35ea3486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: NVIDIA A10G. Max memory: 21.988 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = None,\n",
    "    load_in_4bit = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9a3a192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32be1583",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func(examples):\n",
    "    inputs       = examples[\"md\"]\n",
    "    outputs      = examples[\"status\"]\n",
    "    texts = []\n",
    "    for input, output in zip(inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = prompt.format(instructions, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57bfd43",
   "metadata": {},
   "source": [
    "# Finetune LoRA adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97f857c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f96a18db274a38a8c2eddd6cc34cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(train, split='train')\n",
    "\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dda9bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1900"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb47c940",
   "metadata": {},
   "source": [
    "Note: only training for 50 steps for demo purposes (takes ~10min), obviously would train longer (until validation accuracy increases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c6b6b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53dfcfa1506740da999d5fd0718c7c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "#         num_train_epochs = 3,\n",
    "        max_steps = train_steps,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4642923d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,900 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 50\n",
      " \"-____-\"     Number of trainable parameters = 41,943,040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 12:10, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.992200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.110300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.132400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.883000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.895700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.697900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.691100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.726000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.353900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.441800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.301700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.183200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.935400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.221800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.101800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.032300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.038700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.893100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.587400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.839600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.998700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.914000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.652200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.833900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.642700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.985200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.899200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.794900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.902000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.909000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.908800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.908600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.841100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.739200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.948900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.924700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.667200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.779100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.790300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.926600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.509600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.857700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.774200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.818000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.016500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.888000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73f8973f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lora_model/tokenizer_config.json',\n",
       " 'lora_model/special_tokens_map.json',\n",
       " 'lora_model/tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"lora_model\") # Local saving\n",
    "tokenizer.save_pretrained(\"lora_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe5db1",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7253e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: NVIDIA A10G. Max memory: 21.988 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = None,\n",
    "        load_in_4bit = True,\n",
    "    )\n",
    "FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e50c1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = valid.sample(1)\n",
    "url = sample.Website.iloc[0]\n",
    "md = sample.md.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "919e4f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_string(x: str, n=7000) -> str:\n",
    "    if n < 3:\n",
    "        raise ValueError(\"n must be at least 3\")\n",
    "    if len(x) > n:\n",
    "        return x[: (n - 3)] + \"...\"\n",
    "    return x\n",
    "\n",
    "def extract_response(out):\n",
    "    try:\n",
    "        return out.split(\"<|end_of_text|>\")[0].split(\"Response:\")[1].strip()\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None\n",
    "\n",
    "def predict_batch(mds):\n",
    "    \n",
    "    mds = [limit_string(md) for md in mds]  # super hacky\n",
    "    \n",
    "    lengths = [len(md) for md in mds]\n",
    "    \n",
    "    assert all(x > 5 for x in lengths)\n",
    "    \n",
    "    _formatted = [prompt.format(instructions, md, \"\") for md in mds]\n",
    "    \n",
    "    inputs = tokenizer(_formatted, return_tensors = \"pt\", padding=True).to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(**inputs, max_new_tokens = 32, use_cache = True)\n",
    "    whole_texts = tokenizer.batch_decode(outputs)\n",
    "    return [extract_response(t) for t in whole_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7580184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No jobs', 'No jobs', 'No jobs']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_batch(valid.sample(3).md.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b624fc",
   "metadata": {},
   "source": [
    "# Get Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65182d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched = [valid.md.iloc[i:(i+4)] for i in range(0, num_valid, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fc9109d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [01:38<00:00,  3.94s/it]\n"
     ]
    }
   ],
   "source": [
    "batched_res = [predict_batch(b) for b in tqdm(batched)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fc4dcb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unbatched = [x for b in batched_res for x in b]\n",
    "len(unbatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72c2148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid['llama_results'] = unbatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02c3cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _correct_syntax(x):\n",
    "    if x in [\"Job list\", \"Job open apply\", \"Link to jobs\", \"No jobs\"]:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "510ae286",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid['syntax_correct'] = valid.llama_results.apply(_correct_syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf63aace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No jobs list', 'No jobs\\n\\n###', 'No jobs', 'No jobs found', 'No jobs list']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.sample(5).llama_results.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77fc764",
   "metadata": {},
   "source": [
    "Note: this was the result for training for 5 steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ece5f751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.21), np.float64(0.04))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.syntax_correct.mean(), (valid.results == valid.status).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c52f955",
   "metadata": {},
   "source": [
    "Results for 50 steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8c66a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.66), np.float64(0.49))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.syntax_correct.mean(), (valid.llama_results == valid.status).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c312db",
   "metadata": {},
   "source": [
    "What we really want is precision & recall for job links found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20a574ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(valid.status == \"Link to jobs\"), sum(valid.llama_results == \"Link to jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37111b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0625)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall\n",
    "(valid.llama_results == valid.status)[valid.status == \"Link to jobs\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3679f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision\n",
    "(valid.llama_results == valid.status)[valid.llama_results == \"Link to jobs\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b76ab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.to_csv(\"../data/05_ft_validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fb74f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
